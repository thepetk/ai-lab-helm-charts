{
    "$schema": "https://json-schema.org/draft/2020-12/schema",
    "properties": {
        "application": {
            "properties": {
                "appContainer": {
                    "default": "quay.io/redhat-ai-dev/chatbot:latest",
                    "description": "The image used for the initial chatbot application interface.",
                    "title": "App Container",
                    "type": "string"
                },
                "appPort": {
                    "default": 8501,
                    "description": "The exposed port of the application.",
                    "title": "App Port",
                    "type": "integer"
                }
            },
            "type": "object"
        },
        "gitops": {
            "properties": {
                "gitDefaultBranch": {
                    "default": "main",
                    "description": "The default branch for the chatbot application Github repository.",
                    "title": "Git Default Branch",
                    "type": "string"
                },
                "gitSecretKeyToken": {
                    "default": "password",
                    "description": "The name of the Secret's key with the Github token value.",
                    "title": "Secret Key Token",
                    "type": "string"
                },
                "gitSecretName": {
                    "default": "github-secrets",
                    "description": "The name of the Secret containing the required Github token.",
                    "title": "Secret Name",
                    "type": "string"
                },
                "gitSourceRepo": {
                    "default": "redhat-ai-dev/ai-lab-samples",
                    "description": "The Github Repository with the contents of the ai-lab sample chatbot application. It must be either the 'redhat-ai-dev/ai-lab-samples' or its fork.",
                    "title": "Git Source Repo",
                    "type": "string"
                },
                "githubOrgName": {
                    "description": "[REQUIRED] The Github Organization name that the chatbot application repository will be created into.",
                    "title": "GitHub Org Name",
                    "type": "string"
                },
                "quayAccountName": {
                    "description": "[REQUIRED] The quay.io account that the application image will be pushed.",
                    "title": "Quay Account Name",
                    "type": "string"
                }
            },
            "required": [
                "quayAccountName",
                "githubOrgName"
            ],
            "type": "object"
        },
        "model": {
            "properties": {
                "existingModelServer": {
                    "default": false,
                    "description": "Adds support of an existing model server for the deployed application. If selected it overrides the vLLM & llama.cpp use cases.",
                    "title": "Use Existing Model Server",
                    "type": "boolean"
                },
                "includeModelEndpointSecret": {
                    "default": false,
                    "description": "Adds support for bearer authentication for the existing model server endpoint.",
                    "title": "Existing Model Bearer Authentication Support",
                    "type": "boolean"
                },
                "initContainer": {
                    "default": "quay.io/redhat-ai-dev/granite-7b-lab:latest",
                    "description": "The image used for the initContainer of the model service deployment.",
                    "title": "Init Container",
                    "type": "string"
                },
                "maxModelLength": {
                    "default": 4096,
                    "description": "The maximum sequence length of the model. It is used only for the vllm case and the default value is 4096.",
                    "title": "Model Max Length",
                    "type": "integer"
                },
                "modelEndpoint": {
                    "description": "The endpoint url of the model for the existing model service case. Is used only if existingModelServer is set to true.",
                    "title": "Existing Model Endpoint URL",
                    "type": "string"
                },
                "modelEndpointSecretKey": {
                    "description": "The name of the secret field storing the bearer value for the existing model service if the endpoint requires bearer authentication. Is used only if includeModelEndpointSecret is set to true.",
                    "title": "Existing Model Endpoint Secret Key",
                    "type": "string"
                },
                "modelEndpointSecretName": {
                    "description": "The name of the secret storing the credentials for the existing model service for bearer authentication. Is used only if includeModelEndpointSecret is set to true.",
                    "title": "Existing Model Endpoint Secret Name",
                    "type": "string"
                },
                "modelInitCommand": {
                    "default": "['/usr/bin/install', '/model/model.file', '/shared/']",
                    "description": "The model service initContainer command.",
                    "title": "Init Command",
                    "type": "string"
                },
                "modelName": {
                    "description": "The name of the model. It is used only in the vLLM use case.",
                    "title": "Model Name",
                    "type": "string"
                },
                "modelPath": {
                    "default": "/model/model.file",
                    "description": "The path of the model file inside the model service container.",
                    "title": "Path",
                    "type": "string"
                },
                "modelServiceContainer": {
                    "default": "quay.io/ai-lab/llamacpp_python:latest",
                    "description": "The image used for the model service.",
                    "title": "Service Container",
                    "type": "string"
                },
                "modelServicePort": {
                    "default": 8001,
                    "description": "The exposed port of the model service.",
                    "title": "Service Port",
                    "type": "integer"
                },
                "vllmModelServiceContainer": {
                    "description": "The image used for the model service for the vLLM use case.",
                    "title": "vLLM Image",
                    "type": "string"
                },
                "vllmSelected": {
                    "default": false,
                    "description": "Adds support of vLLM instead of llama_cpp. Be sure that your system has GPU support for this case.",
                    "title": "Use vLLM",
                    "type": "boolean"
                }
            },
            "type": "object"
        }
    },
    "title": "Chatbot AI Sample Helm Chart",
    "type": "object"
}